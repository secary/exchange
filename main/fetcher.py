import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import uuid
from loguru import logger
from config.logger_config import trace_ids  # âœ… å¼•å…¥ trace_idsï¼Œä¸Šä¸‹æ–‡è¿½è¸ª

# è®¾ç½® trace_idï¼ˆåœ¨åˆå§‹åŒ–å‰è®¾å®šï¼‰
trace_id = os.getenv("TRACE_ID_JANUS") or f"JANUS-{uuid.uuid4()}"
trace_ids["janus"].set(trace_id)

# ç»‘å®š loguru loggerï¼ˆé‡è¦ï¼šä¸ºæ—¥å¿—åˆ†ç±»æ·»åŠ æ ‡è¯†ï¼‰
logger = logger.bind(name="janus")

import urllib.request
import urllib.error
import traceback
from bs4 import BeautifulSoup
import time
import random

# å¤šä¸ª User-Agent åˆ—è¡¨
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64)...',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)...',
    'Mozilla/5.0 (X11; Linux x86_64)...',
]

from utils.models import CurrencyMap
from sqlalchemy.orm import sessionmaker
from config.settings import get_engine

# åœ¨å‡½æ•°å¤–åˆå§‹åŒ–ä¸€æ¬¡
Session = sessionmaker(bind=get_engine())
session = Session()
rows = session.query(CurrencyMap).all()
CN2EN = { r.name_cn: r.code_en for r in rows }
session.close()

def askurl(url, timeout=15, retries=3, delay=10):
    import socket
    socket.setdefaulttimeout(timeout)

    for attempt in range(1, retries + 1):
        user_agent = random.choice(USER_AGENTS)
        headers = {'User-Agent': user_agent}
        request = urllib.request.Request(url, headers=headers)

        try:
            logger.debug(f" ç¬¬ {attempt} æ¬¡å°è¯•ï¼ŒURL: {url}, UA: {user_agent}")
            response = urllib.request.urlopen(request, timeout=timeout)
            html = response.read().decode('utf-8')
            logger.debug(f" âœ… æˆåŠŸï¼Œç¬¬ {attempt} æ¬¡ï¼Œè¯·æ±‚çŠ¶æ€ç : {response.getcode()}")
            return html

        except urllib.error.HTTPError as e:
            logger.warning(f" âš ï¸ ç¬¬ {attempt} æ¬¡å¤±è´¥ - HTTPError: {e.code}, {e.reason}")
            logger.debug(f" å“åº”å¤´: {e.headers}")
        except urllib.error.URLError as e:
            logger.warning(f" âš ï¸ ç¬¬ {attempt} æ¬¡å¤±è´¥ - URLError: {e.reason}")
        except TimeoutError as e:
            logger.warning(f" âš ï¸ ç¬¬ {attempt} æ¬¡å¤±è´¥ - TimeoutError: {e}")
        except Exception:
            logger.exception(f" âŒ ç¬¬ {attempt} æ¬¡å¤±è´¥ - æœªçŸ¥å¼‚å¸¸")
            logger.debug(traceback.format_exc())

        if attempt < retries:
            sleep_time = delay + random.uniform(2, 5)
            logger.info(f" å°†åœ¨ {sleep_time:.1f} ç§’åé‡è¯•...")

    logger.error(f" âŒ æ‰€æœ‰ {retries} æ¬¡å°è¯•å‡å¤±è´¥ï¼Œæ”¾å¼ƒè¯·æ±‚ã€‚")
    return None

def get_exchange_rate(url, currencies, save_html=False):
    if not isinstance(currencies, list):
        logger.error("âŒ currencies å‚æ•°å¿…é¡»æ˜¯ä¸€ä¸ªåˆ—è¡¨")
        return {}

    html = askurl(url)
    if not html:
        logger.error("âŒ æœªèƒ½è·å– HTML å†…å®¹")
        return {}
    
    soup = BeautifulSoup(html, "html.parser")
    result = {}

    for currency in currencies:
        target_td = soup.find('td', string=currency)
        if target_td:
            row = target_td.find_parent('tr')
            row_data = [td.get_text(strip=True) for td in row.find_all('td')]
            name_cn = row_data[0]
            name_en = CN2EN.get(name_cn, name_cn)
            result[name_en] = {
                "ç°æ±‡å–å‡ºä»·": row_data[3],
                "æ—¥æœŸ": row_data[6]
            }
        
        else:
            logger.warning(f"âŒ æœªæ‰¾åˆ°åŒ…å« '{currency}' çš„ <td> æ ‡ç­¾")
            
    if save_html:
        timestamp = time.strftime("%Y%m%d_%H%M%S")  # æ­£ç¡®ã€å®‰å…¨çš„æ—¶é—´æ ¼å¼
        file = f'source_{timestamp}.html'
        path = os.path.join('data', 'source', file)
        os.makedirs(os.path.dirname(path), exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨
        with open(path, "w", encoding="utf-8") as f:
            f.write(html)
        logger.info(f"ğŸ“ htmlæºæ–‡ä»¶å·²ä¿å­˜è‡³ {path}")

    logger.debug(f"æ±‡ç‡æŠ“å–ç»“æœ: {result}")
    return result

